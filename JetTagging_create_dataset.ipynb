{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK0wr2onBn4d"
   },
   "source": [
    "# Create Dataset for Jet Tagging @ L1 studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxGwUjLmBn4f"
   },
   "source": [
    "# Load HLS4ML dataset \n",
    "\n",
    "Here, we load the numpy arrays containing the 4D tensors of \"jet-images\" (see https://arxiv.org/pdf/1511.05190.pdf)\n",
    "\n",
    "https://github.com/pierinim/tutorials/blob/master/GGI_Jan2021/Lecture1/Notebook1_ExploreDataset.ipynb\n",
    "\n",
    " * `jetImage` contains the image representation of the jets (more later)\n",
    " * `jetImageECAL` and `jetImageHCAL` are the ECAL- and HCAL-only equivalent images. We will not use them (but you are more than welcome to play with it)\n",
    " * `jetConstituentList` is the list of particles cointained in the jet. For each particle, a list of relevant quantities is stored\n",
    " * `particleFeatureNames` is the list of the names corresponding to the quantities contained in `jetConstituentList`; `jets` is the dataset we consider for the moment\n",
    " * `jetFeatureNames` is the list of the names corresponding to the quantities contained in `jets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1616956528521,
     "user": {
      "displayName": "Andre Sznajder",
      "photoUrl": "https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg",
      "userId": "12562331206892861623"
     },
     "user_tz": -120
    },
    "id": "TcXokNduBn4g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending jetImage_6_150p_40000_50000.h5\n",
      "Keys in H5PY files =  ['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']\n",
      " \n",
      "Jets Features =  [b'j_ptfrac' b'j_pt' b'j_eta' b'j_mass' b'j_tau1_b1' b'j_tau2_b1'\n",
      " b'j_tau3_b1' b'j_tau1_b2' b'j_tau2_b2' b'j_tau3_b2' b'j_tau32_b1'\n",
      " b'j_tau32_b2' b'j_zlogz' b'j_c1_b0' b'j_c1_b1' b'j_c1_b2' b'j_c2_b1'\n",
      " b'j_c2_b2' b'j_d2_b1' b'j_d2_b2' b'j_d2_a1_b1' b'j_d2_a1_b2' b'j_m2_b1'\n",
      " b'j_m2_b2' b'j_n2_b1' b'j_n2_b2' b'j_tau1_b1_mmdt' b'j_tau2_b1_mmdt'\n",
      " b'j_tau3_b1_mmdt' b'j_tau1_b2_mmdt' b'j_tau2_b2_mmdt' b'j_tau3_b2_mmdt'\n",
      " b'j_tau32_b1_mmdt' b'j_tau32_b2_mmdt' b'j_c1_b0_mmdt' b'j_c1_b1_mmdt'\n",
      " b'j_c1_b2_mmdt' b'j_c2_b1_mmdt' b'j_c2_b2_mmdt' b'j_d2_b1_mmdt'\n",
      " b'j_d2_b2_mmdt' b'j_d2_a1_b1_mmdt' b'j_d2_a1_b2_mmdt' b'j_m2_b1_mmdt'\n",
      " b'j_m2_b2_mmdt' b'j_n2_b1_mmdt' b'j_n2_b2_mmdt' b'j_mass_trim'\n",
      " b'j_mass_mmdt' b'j_mass_prun' b'j_mass_sdb2' b'j_mass_sdm1'\n",
      " b'j_multiplicity' b'j_g' b'j_q' b'j_w' b'j_z' b'j_t' b'j_undef']\n",
      " \n",
      "Jet Constituents Features =  [b'j1_px' b'j1_py' b'j1_pz' b'j1_e' b'j1_erel' b'j1_pt' b'j1_ptrel'\n",
      " b'j1_eta' b'j1_etarel' b'j1_etarot' b'j1_phi' b'j1_phirel' b'j1_phirot'\n",
      " b'j1_deltaR' b'j1_costheta' b'j1_costhetarel' b'j1_pdgid']\n",
      " \n",
      "Jet Images =  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "Jet Image Shape =  (10000, 100, 100)\n",
      " \n",
      "Appending jetImage_3_150p_10000_20000.h5\n",
      "Appending jetImage_2_150p_10000_20000.h5\n",
      "Appending jetImage_7_150p_40000_50000.h5\n",
      "Appending jetImage_8_150p_20000_30000.h5\n",
      "Appending jetImage_1_150p_10000_20000.h5\n",
      "Appending jetImage_4_150p_40000_50000.h5\n",
      "Appending jetImage_4_150p_0_10000.h5\n",
      "Appending jetImage_9_150p_20000_30000.h5\n",
      "Appending jetImage_5_150p_40000_50000.h5\n",
      "Appending jetImage_0_150p_10000_20000.h5\n",
      "Appending jetImage_6_150p_10000_20000.h5\n",
      "Appending jetImage_3_150p_0_10000.h5\n",
      "Appending jetImage_3_150p_40000_50000.h5\n",
      "Appending jetImage_2_150p_40000_50000.h5\n",
      "Appending jetImage_7_150p_10000_20000.h5\n",
      "Appending jetImage_8_150p_70000_80000.h5\n",
      "Appending jetImage_1_150p_40000_50000.h5\n",
      "Appending jetImage_4_150p_10000_20000.h5\n",
      "Appending jetImage_8_150p_80000_90000.h5\n",
      "Appending jetImage_5_150p_10000_20000.h5\n",
      "Appending jetImage_0_150p_40000_50000.h5\n",
      "Appending jetImage_9_150p_70000_80000.h5\n",
      "Appending jetImage_9_150p_80000_90000.h5\n",
      "Appending jetImage_2_150p_0_10000.h5\n",
      "Appending jetImage_4_150p_80000_90000.h5\n",
      "Appending jetImage_1_150p_20000_30000.h5\n",
      "Appending jetImage_8_150p_10000_20000.h5\n",
      "Appending jetImage_4_150p_70000_80000.h5\n",
      "Appending jetImage_0_150p_20000_30000.h5\n",
      "Appending jetImage_5_150p_80000_90000.h5\n",
      "Appending jetImage_5_150p_70000_80000.h5\n",
      "Appending jetImage_9_150p_10000_20000.h5\n",
      "Appending jetImage_6_150p_70000_80000.h5\n",
      "Appending jetImage_3_150p_20000_30000.h5\n",
      "Appending jetImage_6_150p_80000_90000.h5\n",
      "Appending jetImage_7_150p_70000_80000.h5\n",
      "Appending jetImage_7_150p_80000_90000.h5\n",
      "Appending jetImage_2_150p_20000_30000.h5\n",
      "Appending jetImage_1_150p_70000_80000.h5\n",
      "Appending jetImage_8_150p_40000_50000.h5\n",
      "Appending jetImage_4_150p_20000_30000.h5\n",
      "Appending jetImage_1_150p_80000_90000.h5\n",
      "Appending jetImage_0_150p_70000_80000.h5\n",
      "Appending jetImage_0_150p_80000_90000.h5\n",
      "Appending jetImage_5_150p_20000_30000.h5\n",
      "Appending jetImage_3_150p_80000_90000.h5\n",
      "Appending jetImage_6_150p_20000_30000.h5\n",
      "Appending jetImage_3_150p_70000_80000.h5\n",
      "Appending jetImage_7_150p_20000_30000.h5\n",
      "Appending jetImage_2_150p_80000_90000.h5\n",
      "Appending jetImage_5_150p_0_10000.h5\n",
      "Appending jetImage_2_150p_70000_80000.h5\n",
      "Appending jetImage_5_150p_30000_40000.h5\n",
      "Appending jetImage_6_150p_50000_60000.h5\n",
      "Appending jetImage_0_150p_0_10000.h5\n",
      "Appending jetImage_7_150p_50000_60000.h5\n",
      "Appending jetImage_4_150p_30000_40000.h5\n",
      "Appending jetImage_4_150p_50000_60000.h5\n",
      "Appending jetImage_7_150p_30000_40000.h5\n",
      "Appending jetImage_6_150p_30000_40000.h5\n",
      "Appending jetImage_5_150p_50000_60000.h5\n",
      "Appending jetImage_0_150p_30000_40000.h5\n",
      "Appending jetImage_1_150p_30000_40000.h5\n",
      "Appending jetImage_2_150p_50000_60000.h5\n",
      "Appending jetImage_8_150p_0_10000.h5\n",
      "Appending jetImage_8_150p_60000_70000.h5\n",
      "Appending jetImage_2_150p_30000_40000.h5\n",
      "Appending jetImage_7_150p_0_10000.h5\n",
      "Appending jetImage_1_150p_50000_60000.h5\n",
      "Appending jetImage_9_150p_60000_70000.h5\n",
      "Appending jetImage_0_150p_50000_60000.h5\n",
      "Appending jetImage_3_150p_30000_40000.h5\n",
      "Appending jetImage_4_150p_60000_70000.h5\n",
      "Appending jetImage_9_150p_0_10000.h5\n",
      "Appending jetImage_5_150p_60000_70000.h5\n",
      "Appending jetImage_6_150p_60000_70000.h5\n",
      "Appending jetImage_6_150p_0_10000.h5\n",
      "Appending jetImage_7_150p_60000_70000.h5\n",
      "Appending jetImage_1_150p_60000_70000.h5\n",
      "Appending jetImage_8_150p_50000_60000.h5\n",
      "Appending jetImage_0_150p_60000_70000.h5\n",
      "Appending jetImage_9_150p_50000_60000.h5\n",
      "Appending jetImage_1_150p_0_10000.h5\n",
      "Appending jetImage_9_150p_30000_40000.h5\n",
      "Appending jetImage_3_150p_60000_70000.h5\n",
      "Appending jetImage_8_150p_30000_40000.h5\n",
      "Appending jetImage_2_150p_60000_70000.h5\n",
      "Target shape = (880000, 5)\n",
      "Jet Constituents shape = (880000, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# for pT, eta_rel, phi_rel\n",
    "#   myJetConstituentList = np.array(f.get(\"jetConstituentList\")[:,:,[5,8,11]])\n",
    "# for px, py, pz\n",
    "#   myJetConstituentList = np.array(f.get(\"jetConstituentList\")[:,:,[0,1,2]])\n",
    "#   myJetConstituentList = np.array(f.get(\"jetConstituentList\"))\n",
    "#\n",
    "# Jet Constituents Features =  [0='j1_px', 1='j1_py', 2='j1_pz', 3='j1_e', 4='j1_erel', 5='j1_pt', 6='j1_ptrel',\n",
    "#                         7='j1_eta', 8='j1_etarel', 9='j1_etarot', 10='j1_phi', 11='j1_phirel', 12='j1_phirot',\n",
    "#                         13='j1_deltaR', 14='j1_costheta', 15='j1_costhetarel', 16='j1_pdgid']\n",
    "\n",
    "#Data PATH\n",
    "TRAIN_PATH = '/Users/sznajder/WorkM1/workdir/data/hls4ml_LHCjet_150p/'\n",
    "\n",
    "\n",
    "\n",
    "first=True\n",
    "for file in os.listdir(TRAIN_PATH):\n",
    "  print(\"Appending %s\" %file)\n",
    "\n",
    "  with h5py.File(TRAIN_PATH+file, 'r') as data:\n",
    "    if first : \n",
    "        first=False\n",
    "        jetConstituent = data['jetConstituentList'][:,:,[5,8,11]]\n",
    "        target = data['jets'][:,-6:-1]\n",
    "        print(\"Keys in H5PY files = \",list( data.keys() ))\n",
    "        print(\" \")\n",
    "        featurenames = data.get('jetFeatureNames')\n",
    "        print(\"Jets Features = \",featurenames[:])\n",
    "        print(\" \")\n",
    "        featurenames = data.get('particleFeatureNames')\n",
    "        print(\"Jet Constituents Features = \",featurenames[:])\n",
    "        print(\" \")\n",
    "        images = data.get('jetImage')\n",
    "        print(\"Jet Images = \",images[:])        \n",
    "        print(\"Jet Image Shape = \",images.shape)   \n",
    "        print(\" \")\n",
    "    else:\n",
    "         # Read (Pt,Etarel,Phirel)\n",
    "        jetConstituent = np.concatenate( [ jetConstituent, data['jetConstituentList'][:,:,[5,8,11]] ] , axis=0 )\n",
    "        target   = np.concatenate( [ target, data['jets'][:,-6:-1] ] , axis=0 )\n",
    "\n",
    "print(\"Target shape =\", target.shape)\n",
    "print(\"Jet Constituents shape =\", jetConstituent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Image dataset labels ( ONE HOT ENCODING )\n",
    "\n",
    "Jets can be converted to images considering the (&eta;, &phi;) plane, centered along the axis direction and binned.\n",
    "In our case, we consider a square of 1.6x1.6 in size (because the jet size is R=0.8) binned in 100x100 equal-size 'cells'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is incorporated in the `['g', 'q', 'w', 'z', 't']` vector of boolean, taking the form\n",
    "- `[1, 0, 0, 0, 0]` for gluons\n",
    "- `[0, 1, 0, 0, 0]` for quarks\n",
    "- `[0, 0, 1, 0, 0]` for Ws\n",
    "- `[0, 0, 0, 1, 0]` for Zs\n",
    "- `[0, 0, 0, 0, 1]` for tops\n",
    "\n",
    "This is what is called 'one-hot' encoding of a descrete label (typical of ground truth for classification problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out Pt<2GeV constituents and Shuffles constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3265,
     "status": "ok",
     "timestamp": 1616956528521,
     "user": {
      "displayName": "Andre Sznajder",
      "photoUrl": "https://lh3.googleusercontent.com/-Bujzmul3q4w/AAAAAAAAAAI/AAAAAAAAA30/Zzdg4zcPB-8/s64/photo.jpg",
      "userId": "12562331206892861623"
     },
     "user_tz": -120
    },
    "id": "YAJhuubTBn4k",
    "outputId": "8dc7af15-bbc1-4421-861a-72dee1979a30"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jetConstituent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange, reduce, repeat\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert target format from one-hot encoding to single neuron\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#target = np.argmax(target, axis=1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# The dataset is N_jets x N_constituents x N_features\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m njet     \u001b[38;5;241m=\u001b[39m \u001b[43mjetConstituent\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m nconstit \u001b[38;5;241m=\u001b[39m jetConstituent\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m nfeat    \u001b[38;5;241m=\u001b[39m jetConstituent\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jetConstituent' is not defined"
     ]
    }
   ],
   "source": [
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# Convert target format from one-hot encoding to single neuron\n",
    "#target = np.argmax(target, axis=1)\n",
    "\n",
    "# The dataset is N_jets x N_constituents x N_features\n",
    "njet     = jetConstituent.shape[0]\n",
    "nconstit = jetConstituent.shape[1]\n",
    "nfeat    = jetConstituent.shape[2]\n",
    "\n",
    "\n",
    "# Filter out constituents with Pt<2GeV\n",
    "Ptmin =2. \n",
    "constituents = np.zeros((njet, nconstit, nfeat) , dtype=np.float32) \n",
    "ij=0\n",
    "max_constit=0\n",
    "for j in range(njet):\n",
    "    ic=0\n",
    "    for c in range(nconstit):\n",
    "        if ( jetConstituent[j,c,0] < Ptmin ):\n",
    "            continue\n",
    "        constituents[ij,ic,:] = jetConstituent[j,c,:] \n",
    "        ic+=1\n",
    "    if (ic > 0):\n",
    "        if ic > max_constit: max_constit=ic\n",
    "        target[ij,:]=target[j,:] # assosicate the correct target a given graph \n",
    "        ij+=1\n",
    "\n",
    "\n",
    "# Resizes the jets constituents and target arrays        \n",
    "jetConstituent = constituents[0:ij,0:max_constit,:]\n",
    "target = target[0:ij,:]\n",
    "\n",
    "\n",
    "# Restric the number of constituents to a maximum of NMAX\n",
    "nmax = 8\n",
    "jetConstituent = jetConstituent[:,0:nmax,:]\n",
    "\n",
    "# The dataset is N_jets x N_constituents x N_features\n",
    "njet     = jetConstituent.shape[0]\n",
    "nconstit = jetConstituent.shape[1]\n",
    "nfeat    = jetConstituent.shape[2]\n",
    "\n",
    "\n",
    "print('Number of jets =',njet)\n",
    "print('Number of constituents =',nconstit)\n",
    "print('Number of features =',nfeat)\n",
    "\n",
    "\n",
    "# Shuffles jet constituents\n",
    "print(\"Before --->> jetConstituent[0,0:4,0] = \",jetConstituent[0,0:4,0])\n",
    "for i in range(jetConstituent.shape[0]):\n",
    "  jetConstituent[i] = jetConstituent[i, np.random.permutation(nconstit), :]\n",
    "print(\"After --->> jetConstituent[0,0:4,0] = \",jetConstituent[0,0:4,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into testing and training dataset\n",
    "\n",
    "We will split the data into two parts (one for training+validation and one for testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = jetConstituent\n",
    "Y = target\n",
    "del jetConstituent , target\n",
    "\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "\n",
    "print(X_train_val.shape, X_test.shape, Y_train_val.shape, Y_test.shape)\n",
    "\n",
    "print('number of G jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==0 ))\n",
    "print('number of Q jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==1 ))\n",
    "print('number of W jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==2 ))\n",
    "print('number of Z jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==3 ))\n",
    "print('number of T jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==4 ))\n",
    "\n",
    "\n",
    "print('number of G jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==0 ))\n",
    "print('number of Q jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==1 ))\n",
    "print('number of W jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==2 ))\n",
    "print('number of Z jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==3 ))\n",
    "print('number of T jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==4 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves the DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"../../data/X_train_val_nconst_{}\".format(nconstit), X_train_val)\n",
    "np.save(\"../../data/X_test_nconst_{}\".format(nconstit)     , X_test)\n",
    "np.save(\"../../data/Y_train_val_nconst_{}\".format(nconstit), Y_train_val)\n",
    "np.save(\"../../data/Y_test_nconst_{}\".format(nconstit)     , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "JetTagging_MLP_TFKeras.ipynb",
   "provenance": [
    {
     "file_id": "1_LtW5Af1ruCzp6IH18NNj2K3Vbgqto-F",
     "timestamp": 1613800914899
    },
    {
     "file_id": "https://github.com/thongonary/machine_learning_vbscan/blob/master/5-conv2d.ipynb",
     "timestamp": 1551264063701
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
